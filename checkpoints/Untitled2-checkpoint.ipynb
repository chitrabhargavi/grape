{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "#Load the Image\n",
    "imgo = cv2.imread('dataset/train/Black_rot/00cab05d-e87b-4cf6-87d8-284f3ec99626___FAM_B.Rot 3244_final_masked.jpg')\n",
    "height, width = imgo.shape[:2]\n",
    "\n",
    "#Create a mask holder\n",
    "mask = np.zeros(imgo.shape[:2],np.uint8)\n",
    "\n",
    "#Grab Cut the object\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "\n",
    "#Hard Coding the Rect… The object must lie within this rect.\n",
    "rect = (10,10,width-10,height-10)\n",
    "cv2.grabCut(imgo,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
    "mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img1 = imgo*mask[:,:,np.newaxis]\n",
    "\n",
    "#Get the background\n",
    "background = imgo - img1\n",
    "\n",
    "#Change all pixels in the background that are not black to white\n",
    "background[np.where((background > [0,0,0]).all(axis = 2))] =[255,255,255]\n",
    "\n",
    "#Add the background and the image\n",
    "final = background + img1\n",
    "\n",
    "#To be done – Smoothening the edges….\n",
    "\n",
    "cv2.imshow('image', img1 )\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('tt',img)\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh1 = cv2.threshold(img, 120, 255, cv2.THRESH_TOZERO_INV) \n",
    "cv2.imshow('tt',thresh1)\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh1 = cv2.threshold(img,60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  \n",
    "cv2.imshow('tt',thresh1)\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh1 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                          cv2.THRESH_BINARY, 199, 5) \n",
    "  \n",
    "thresh2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                          cv2.THRESH_BINARY, 199, 5) \n",
    "  \n",
    "# the window showing output images \n",
    "# with the corresponding thresholding  \n",
    "# techniques applied to the input image \n",
    "cv2.imshow('Adaptive Mean', thresh1) \n",
    "cv2.imshow('Adaptive Gaussian', thresh2) \n",
    "\n",
    "# De-allocate any associated memory usage   \n",
    "if cv2.waitKey(0) & 0xff == 27:  \n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8) \n",
    "img_erosion = cv2.erode(img, kernel, iterations=1) \n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "cv2.imshow('tt1',img_erosion)\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(imgo, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "# preparing the mask to overlay \n",
    "mask = cv2.inRange(hsv, (36, 25, 25), (70, 255,255)) \n",
    "\n",
    "# The black region in the mask has the value of 0, \n",
    "# so when multiplied with original image removes all non-blue regions \n",
    "result = cv2.bitwise_and(imgo, imgo, mask = mask) \n",
    "\n",
    "cv2.imshow('frame', imgo) \n",
    "cv2.imshow('mask', mask) \n",
    "cv2.imshow('result', result) \n",
    "# De-allocate any associated memory usage   \n",
    "if cv2.waitKey(0) & 0xff == 27:  \n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contours' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ea926b188770>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstencil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillPoly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstencil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstencil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'contours' is not defined"
     ]
    }
   ],
   "source": [
    "contours, image = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(gs,contours,-1,(0,0,255),1)\n",
    "stencil = np.zeros(imgo.shape).astype(imgo.dtype)\n",
    "color = [255, 255, 255]\n",
    "cv2.fillPoly(stencil, contours, color)\n",
    "result = cv2.bitwise_and(imgo, stencil)\n",
    "cv2.imshow('result', result) \n",
    "# De-allocate any associated memory usage   \n",
    "if cv2.waitKey(0) & 0xff == 27:  \n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcl",
   "language": "python",
   "name": "tcl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
